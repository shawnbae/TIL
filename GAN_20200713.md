# GAN

## 1. GAN(Normal)

Normal Distribution으로부터 데이터를 샘플링하여 만들어낸 fake date와 실제 데이터를 비교한다.

> Discriminator Network 생성

```python
D_Wh= tf.Variable(tf.random.normal([nInput, nDHidden]), name= 'D_Wh')
D_Bh= tf.Variable(tf.random.normal(shape= [nDHidden]), name= 'D_Bh')
D_Wo= tf.Variable(tf.random.normal([nHidden, nDOutput]), name= 'D_Wo')
D_Bo= tf.Variable(tf.random.normal(shape= [nDOutput]), name= 'D_Bo')
thetaD= [D_Wh, D_Bh, D_Wo, D_Bo]
```

> Generator Network 생성

```python
G_Wh = tf.Variable(tf.random.normal([nGInput, nGHidden]), name='G_Wh')
G_Bh = tf.Variable(tf.random.normal(shape=[nGHidden]), name='G_Bh')
G_Wo = tf.Variable(tf.random.normal([nGHidden, nGOutput]), name='G_Wo')
G_Bo = tf.Variable(tf.random.normal(shape=[nGOutput]), name='G_Bo')
```

> low-level tensorflow를 이용한 modeling

```python
def Discriminator(x):
    D_Ho = tf.nn.relu(tf.matmul(x, D_Wh) + D_Bh)
    D_Out = tf.matmul(D_Ho, D_Wo) + D_Bo
    return tf.nn.sigmoid(D_Out)

def Generator(z):
    G_Ho = tf.nn.relu(tf.matmul(z, G_Wh) + G_Bh)
    G_Out = tf.matmul(G_Ho, G_Wo) + G_Bo
    return G_Out

def getNoise(m, n=nGInput):
    z = np.random.uniform(-1., 1., size=[m, n]).astype('f')
    return z

def lossD(x, z):
    Gz = Generator(z)
    Dx = Discriminator(x)
    DGz = Discriminator(Gz)
    
    return -tf.reduce_mean(myLog(Dx) + myLog(1 - DGz))

def lossG(z):
    Gz = Generator(z)
    DGz = Discriminator(Gz)

    return tf.reduce_mean(myLog(1 - DGz))

opt = optimizers.Adam(learning_rate = 0.0005)
```

```python
histLossD= []
histLossG- []
histKL= []
for i in range(3000):
    for bx in batchDS:
        bz= getNoise(m=bx.shape[0], n=nGInput)
        
        opt.minimize(lambda: lossD(bx,bz), var_list=thetaD)
        opt.minimize(lambda: lossG(bz), var_list= thetaG)
        
    if i % 10==0:
        p, q, kld= KL(bx, Generator(bz))
        histKL.append(kld)
        histLossD.append(lossD(bx,bz))
        histLossG.append(lossG(bz))
```

