# GAN

## 1. GAN(Normal)

Normal Distribution으로부터 데이터를 샘플링하여 만들어낸 fake date와 실제 데이터를 비교한다.

> Discriminator Network 생성

```python
D_Wh= tf.Variable(tf.random.normal([nInput, nDHidden]), name= 'D_Wh')
D_Bh= tf.Variable(tf.random.normal(shape= [nDHidden]), name= 'D_Bh')
D_Wo= tf.Variable(tf.random.normal([nHidden, nDOutput]), name= 'D_Wo')
D_Bo= tf.Variable(tf.random.normal(shape= [nDOutput]), name= 'D_Bo')
thetaD= [D_Wh, D_Bh, D_Wo, D_Bo]
```

> Generator Network 생성

```python
G_Wh = tf.Variable(tf.random.normal([nGInput, nGHidden]), name='G_Wh')
G_Bh = tf.Variable(tf.random.normal(shape=[nGHidden]), name='G_Bh')
G_Wo = tf.Variable(tf.random.normal([nGHidden, nGOutput]), name='G_Wo')
G_Bo = tf.Variable(tf.random.normal(shape=[nGOutput]), name='G_Bo')
```

> low-level tensorflow를 이용한 modeling

```python
def Discriminator(x):
    D_Ho = tf.nn.relu(tf.matmul(x, D_Wh) + D_Bh)
    D_Out = tf.matmul(D_Ho, D_Wo) + D_Bo
    return tf.nn.sigmoid(D_Out)

def Generator(z):
    G_Ho = tf.nn.relu(tf.matmul(z, G_Wh) + G_Bh)
    G_Out = tf.matmul(G_Ho, G_Wo) + G_Bo
    return G_Out

def getNoise(m, n=nGInput):
    z = np.random.uniform(-1., 1., size=[m, n]).astype('f')
    return z

def lossD(x, z):
    Gz = Generator(z)
    Dx = Discriminator(x)
    DGz = Discriminator(Gz)
    
    return -tf.reduce_mean(myLog(Dx) + myLog(1 - DGz))

def lossG(z):
    Gz = Generator(z)
    DGz = Discriminator(Gz)

    return tf.reduce_mean(myLog(1 - DGz))

opt = optimizers.Adam(learning_rate = 0.0005)
```

```python
histLossD= []
histLossG- []
histKL= []
for i in range(3000):
    for bx in batchDS:
        bz= getNoise(m=bx.shape[0], n=nGInput)
        
        opt.minimize(lambda: lossD(bx,bz), var_list=thetaD)
        opt.minimize(lambda: lossG(bz), var_list= thetaG)
        
    if i % 10==0:
        p, q, kld= KL(bx, Generator(bz))
        histKL.append(kld)
        histLossD.append(lossD(bx,bz))
        histLossG.append(lossG(bz))
```

```python
def Discriminator(x):
    D_Ho= tf.nn.relu(tf.matmul(x, D_Wh)+D_Bh)
    D_Out= tf.matmul(D_Ho, D_Wo) +D_Bo
    return tf.nn.sigmoid(D_Out)

def Generator(z):
    G_Ho= tf.nn.relu(tf.matmul(z, G_Wh)+ G_Bh)
    G_Out= tf.matmul(G_Ho, G_Wo)+G_Bo
    return G_Out

def getNoise(m, n=nGInput):
    z= np.random.uniform(-1.,1.,size=[m,n]).astype('f')
    return z

def lossD(x, z):
    Gz= Generator(z)
    Dx= Discriminator(x)
    DGz= Discriminator(Gz)
    
    return -tf.reduce_mean(myLog(Dx)+myLog(1-DGz))

def lossG(z):
    Gz= Generator(z)
    DGz= Discriminator(Gz)
    
    return -tf.reduce_mean(myLog(1-DGz))

opt= optimizers.Adam(learning_rate = 0.0005)
```

## 2. GAN(Keras functional API)

keras에서 functional API형태로 구현한 GAN이다. keras의 경우 기본적으로 supervised learning에 특화되어있다. 따라서 기본적으로 unsupervised learning인 GAN을 학습시키기 위해서는 별도의 labeling을 통한 방법론이 필요하다.



> 필요한 tensorflow 객체들 불러오기

```python
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras import backend as K
tf.compat.v1.disable_eager_execution()
```

tf.compat.v1.disable_eager_execution() 은 없으면 속도가 늦어지므로 꼭 입력할 것. 과거 tf 1버전은 빠르나 코딩이 어렵다는 단점이 있었는데 tf 2버전으로 들어오면서 그래프 단위로 동시실행(eager_mode)하게되어 편하나 속도가 늦어졌다. 해당 코드는 eager_mode를 꺼달라는 뜻으로 학습 속도를 빠르게 할 수 있다.

>Discriminator 정의하기.

```python
def BuildDiscriminator():
    x = Input(batch_shape= (None, nDInput))
    h= Dense(nDHidden, activation= 'relu')(x)
    Dx= Dense(nDOutput, activation= 'sigmoid')(h)
    model= Model(x, Dx)
    model.compile(loss= 'binary_crossentropy', optimizer= MyOptimizer(0.001))
    return model
```

> Generator 정의하기. 이 때 Discriminator와 차이점은 compile을 시키지 않는다는 것이다. 즉, Generator는 학습을 위한 층이 아니기 때문에 compile시키지 않는다. 

```python
def BuildGenerator():
    z= Input(batch_shape= (None, nGInput))
    h= Dense(nGHidden, activation= 'relu')(z)
    Gz= Dense(nGOutput, activation= 'linear')(h)
    return Model(z, Gz)
```

> Generator와 Discriminator를 잇는 GAN을 만든다. 이 때, Discriminator에 trainable False를 지정해준 이유는 Generator를 학습하는 데 있어 그 결과를 Discriminator에 전달해주지 않게 하기 위함이다.

```python
def BuildGAN(D, G):
    D.trainable= False # Discriminator는 학습하지 말라
    z= Input(batch_shape= (None, nGInput))
    Gz= G(z)
    DGz= D(Gz)
    
    model= Model(z, DGz)
    model.compile(loss= 'binary_crossentropy', optimizer= MyOptimizer(0.0005))
    return model
```

> 연결한다.

```python
Discriminator = BuildDiscriminator()
Generator = BuildGenerator()
GAN = BuildGAN(Discriminator, Generator)
```

> 학습한다.

```python
for epoch in range(1000):
    for n in range(nBatchCnt):
        nFrom= n*nBatchSize
        nTo= n*nBatchSize + nBatchSize
        
        if n== nBatchCnt -1:
            nTo= realData.shape[0]
        bx= realData[nFrom:nTo] # 진짜 데이터
        bz= getNoise(m=bx.shape[0], n=nGInput) # Random Noise
        Gz= Generator.predict(bz) # Random Noise를 통해 생성된 가짜 데이터
        
        target= np.zeros(bx.shape[0]*2)
        target[:bx.shape[0]]=0.9 # 일반적으로 1
        target[bx.shape[0]:]=0.1 # 일반적으로 0
        bx_Gz= np.concatenate([bx, Gz])
        Dloss= Discriminator.train_on_batch(bx_Gz, target)
        
        target= np.zeros(bx.shape[0])
        target[:]= 0.9
        Gloss= GAN.train_on_batch(bz, target)
        
    if epoch%10 == 0:
        z= getNoise(m=realData.shape[0], n=nGInput)
        fakeData= Generator.predict(z)
        kd= KL(realData, fakeData)
```

> 이 때 일반적인 학습 함수인 fit 대신 train_on_batch를 사용한다.  fit이라는 함수는 epoch마다 연산하기 때문에 batch단위로 학습하는 train_on_batch보다 느리다.

## 3. DCGAN

이미지 학습에 최적화된 DCGAN(Deep convolutional GAN)이다.

```python
from tensorflow.keras.layers import Activation, Dense, Input
from tensorflow.keras.layers import Conv2D, Flatten
from tensorflow.keras.layers import Reshape, Conv2DTranspose
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.models import Model
from tensorflow.keras.datasets import mnist
```

> 필요한 패키지들을 불러온다.

``` python
def build_generator(inputs, image_size):
    image_resize= image_size // 4
    
    kernel_size= 5
    layer_filters= [128, 64, 32, 1]
    
    x= Dense(image_resize * image_resize * layer_filters[0])(inputs)
    x= Reshape((image_resize, image_resize, layer_filters[0]))(x)
    
    for filters in layer_filters:
        if filters > layer_filters[-2]:
            strides=2
        else:
            strides=1
        x= BatchNormalization()(x)
        x= Activation('relu')(x)
        x= Conv2DTranspose(filters= filters,
                          kernel_size= kernel_size,
                          strides= strides,
                          padding= 'same')(x)
    x= Activation('sigmoid')(x)
    generator= Model(inputs, x, name= 'generator')
    return generator
```

> Generator를 생성하는 함수를 구축한다. 이 때 반복되는 층이 많으므로 반복문을 사용하여 층을 설계한다.

```python
def build_discriminator(inputs):
    kernel_size= 5
    layer_filters= [32, 64, 128, 256]
    
    x= inputs
    for filters in layer_filters:
        if filters == layer_filters[-1]:
            strides=1
        else:
            strides=2
        x= LeakyReLU(alpha= 0.2)(x)
        x= Conv2D(filters= filters,
                 kernel_size= kernel_size,
                 strides= strides,
                 padding= 'same')(x)
    x= Flatten()(x)
    x= Dense(1)(x)
    x= Activation('sigmoid')(x)
    discriminator= Model(inputs, x, name= 'discriminator')
    return discriminator
```

> Discriminator를 생성하는 함수를 구축한다.

```python
def train(models, x_train, params):
    genenrator, discriminator, adversarial= models    
    batch_size, latent_size, train_steps, model_name= params    
    train_size= x_train.shape[0]
    for i in range(train_steps):
        rand_indexes= np.random.randint(0, train_size, size= batch_size)
        real_images= x_train[rand_indexes]        
        noise= np.random.uniform(-1.0,
                                1.0,
                                size= [batch_size, latent_size])
        fake_images= generator.predict(noise)
        x= np.concatenate((real_images, fake_images))
        y= np.ones([2*batch_size,1])
        y[batch_size:, :]= 0.0
        
        loss, acc= discriminator.train_on_batch(x, y)
    generator.save(model_name + ".h5")
```

> Discriminator를 학습한다.

```python
def build_and_train_models(load_W= False, train_steps= 100):
    model_name= 'dcgan_mnist'
    
    batch_size=64
    lr=2e-4
    decay= 6e-8
    input_shape= (image_size, image_size, 1)
    
    inputs= Input(shape= input_shape, name= 'discriminator_input')
    discriminator= build_discriminator(inputs)
    optimizer= RMSprop(lr=lr, decay=decay)
    discriminator.compile(loss= 'binary_crossentropy',
                         optimizer=optimizer,
                         metrics=['accuracy'])
    discriminator.summary()
    
    if load_W:
        discriminator.load_weights("dataset/dcgan_D.h5")
    
    optimizer= RMSprop(lr=lr*0.5, decay=decay*0.5)
    discriminator.trainable= False
    adversarial= Model(inputs,
                      discriminator(generator(inputs)),
                      name= model_name)
    adversarial.compile(loss='binary_crossentropy',
                       optimizer=optimizer,
                       metrics=['accuracy'])
    adversarial.summary()
    
    models= (generator, discriminator, adversarial)
    params= (batch_size, latent_size, train_steps, model_name)
    train(models, x_train, params)
    
    discriminator.save_weights('dataset/dcgan_D.h5')
    generator.save_weights('dataset/dcgan_G.h5')
```

> 전체 GAN을 학습한다.

```profile
Model: "discriminator"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
discriminator_input (InputLa [(None, 28, 28, 1)]       0         
_________________________________________________________________
leaky_re_lu (LeakyReLU)      (None, 28, 28, 1)         0         
_________________________________________________________________
conv2d (Conv2D)              (None, 14, 14, 32)        832       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 7, 7, 64)          51264     
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 4, 4, 128)         204928    
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    
_________________________________________________________________
flatten (Flatten)            (None, 4096)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 4097      
_________________________________________________________________
activation (Activation)      (None, 1)                 0         
=================================================================
Total params: 1,080,577
Trainable params: 1,080,577
Non-trainable params: 0
_________________________________________________________________
Model: "generator"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
z_input (InputLayer)         [(None, 100)]             0         
_________________________________________________________________
dense_5 (Dense)              (None, 6272)              633472    
_________________________________________________________________
reshape (Reshape)            (None, 7, 7, 128)         0         
_________________________________________________________________
batch_normalization (BatchNo (None, 7, 7, 128)         512       
_________________________________________________________________
activation_1 (Activation)    (None, 7, 7, 128)         0         
_________________________________________________________________
conv2d_transpose (Conv2DTran (None, 14, 14, 128)       409728    
_________________________________________________________________
batch_normalization_1 (Batch (None, 14, 14, 128)       512       
_________________________________________________________________
activation_2 (Activation)    (None, 14, 14, 128)       0         
_________________________________________________________________
conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        204864    
_________________________________________________________________
batch_normalization_2 (Batch (None, 28, 28, 64)        256       
_________________________________________________________________
activation_3 (Activation)    (None, 28, 28, 64)        0         
_________________________________________________________________
conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        51232     
_________________________________________________________________
batch_normalization_3 (Batch (None, 28, 28, 32)        128       
_________________________________________________________________
activation_4 (Activation)    (None, 28, 28, 32)        0         
_________________________________________________________________
conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         801       
_________________________________________________________________
activation_5 (Activation)    (None, 28, 28, 1)         0         
=================================================================
Total params: 1,301,505
Trainable params: 1,300,801
Non-trainable params: 704
_________________________________________________________________
Model: "dcgan_mnist"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
z_input (InputLayer)         [(None, 100)]             0         
_________________________________________________________________
generator (Model)            (None, 28, 28, 1)         1301505   
_________________________________________________________________
discriminator (Model)        (None, 1)                 1080577   
=================================================================
Total params: 2,382,082
Trainable params: 1,300,801
Non-trainable params: 1,081,281
_________________________________________________________________
```

> 모델 구조는 다음과 같다.

